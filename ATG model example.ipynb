{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy as sp\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "nlp = sp.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Newsarticles8.csv')\n",
    "df = df.dropna(subset=['text']) ## drop missing values \n",
    "df = df.dropna(subset=['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model:\n",
    "    def __init__(self, corpus):\n",
    "        self.vectorizer = TfidfVectorizer(analyzer='word', stop_words='english')\n",
    "        self.vectorizer.fit_transform(corpus)\n",
    "        self.feature_names = np.array(self.vectorizer.get_feature_names())\n",
    "        \n",
    "    def generate_titles(self, text, n_titles, n_keywords, min_lenght, max_lenght):\n",
    "        top_keywords = self.get_keywords(text, n_keywords)\n",
    "        keywords, _ = zip(*top_keywords)\n",
    "        candidates_with_sim, new_keywords = self.get_sentence_candidates_with_sim(text, top_keywords, 20)\n",
    "        keywords_ext = new_keywords + list(keywords)\n",
    "        return self.get_generated_titles(candidates_with_sim, keywords_ext, n_titles, min_lenght, max_lenght)\n",
    "    \n",
    "    def get_keywords(self, text, n=10):\n",
    "        query_transformed = self.vectorizer.transform([text]).toarray()\n",
    "        keyword_index = np.argsort(query_transformed[0])[::-1]\n",
    "        rank = query_transformed[0][keyword_index[:n]]\n",
    "        keywords = self.feature_names[keyword_index[:n]]\n",
    "        return list(zip(keywords, rank))\n",
    "    \n",
    "    def get_generated_titles(self, candidates, keywords, n, lower_l, upper_l):\n",
    "        list_of_sentences = []\n",
    "        for sentence in candidates[:n]:\n",
    "            doc = nlp(sentence[0])\n",
    "            list_of_aux = self.get_AUX(doc, keywords)\n",
    "            list_of_det = self.get_DET(doc)\n",
    "            list_of_adp = self.get_ADP(doc, keywords)\n",
    "            list_of_acc = self.get_accordingtos(doc)\n",
    "            to_delete = list(set(list_of_aux) | set(list_of_det) | set(list_of_acc) | set(list_of_adp))\n",
    "            resulting_sentence = ' '.join([tok.orth_ for tok in doc if tok.i not in to_delete]).replace(\" '\", \"'\").replace(' .', '.').replace(\" - \", \"-\").replace(\" ,.\", \".\").replace(\",.\", \".\").replace(\" ,\", \",\").replace(\" :\", \":\").replace('. \"', '\"').replace(\" n't\", \"n't\")\n",
    "            if (len(resulting_sentence.split()) <= upper_l and len(resulting_sentence.split()) > lower_l):\n",
    "                list_of_sentences.append(resulting_sentence[0].upper() + resulting_sentence[1:])\n",
    "                #print(resulting_sentence[0].upper() + resulting_sentence[1:])\n",
    "\n",
    "        return list_of_sentences\n",
    "    \n",
    "    def sentence_score_with_sim(self, sentence, top_keywords, cutoff):\n",
    "        keywords, keywords_score = zip(*top_keywords)\n",
    "        tokenized_keywords = nlp(' '.join(keywords))\n",
    "        new_keywords = []\n",
    "        score = 0\n",
    "        for tok in sentence:\n",
    "            if not tok.is_stop:\n",
    "                for keytok in tokenized_keywords:\n",
    "                    if tok.orth_ == keytok.orth_:\n",
    "                        score += keywords_score[keytok.i]\n",
    "                    else: \n",
    "                        if tok.similarity(keytok) > cutoff:\n",
    "                            new_keywords.append(tok.orth_)\n",
    "                            score += tok.similarity(keytok) * keywords_score[keytok.i]\n",
    "        return score, new_keywords\n",
    "\n",
    "\n",
    "    def get_sentence_candidates_with_sim(self, content, top_keywords, n):\n",
    "        doc = nlp(content)\n",
    "        sents = list(doc.sents)\n",
    "        sentence_keywords = []\n",
    "        for sentence in sents:\n",
    "            score, new_keywords = self.sentence_score_with_sim(sentence, top_keywords, 0.7)\n",
    "            sentence_keywords.append((sentence.text, score))\n",
    "        return sorted(sentence_keywords, key=lambda tup: tup[1], reverse=True)[:n], new_keywords\n",
    "    \n",
    "    def get_ADP(self, doc, keywords):\n",
    "        to_delete = []\n",
    "        for token in doc:\n",
    "            if token.pos_ == 'ADP' and token.text != 'to' and token.text != 'of' and token.text not in keywords:\n",
    "                tmp = []\n",
    "                keyword_found = False\n",
    "                for tok in token.subtree:\n",
    "                    if tok.orth_ in keywords:\n",
    "                        keyword_found = True\n",
    "                        break\n",
    "                    tmp.append(tok.i)\n",
    "                if not (keyword_found):\n",
    "                    to_delete = tmp\n",
    "        return to_delete\n",
    "                    \n",
    "    def get_AUX(self, doc, keywords):\n",
    "        to_delete = []\n",
    "        #print(\"AUX: \")\n",
    "        for token in doc:\n",
    "            if token.pos_ == 'AUX' and token.orth_ not in keywords:\n",
    "                tmp = []\n",
    "                keyword_found = False\n",
    "                for tok in token.subtree:\n",
    "                    if tok.orth_ in keywords:\n",
    "                        keyword_found = True\n",
    "                        break\n",
    "                    tmp.append(tok.i)\n",
    "                if not (keyword_found):\n",
    "                    to_delete = tmp\n",
    "        return to_delete\n",
    "\n",
    "    def get_accordingtos(self, doc):\n",
    "        to_delete = []\n",
    "        for token in doc:\n",
    "            if token.text in ('according', 'According'):\n",
    "                for tok in token.subtree:\n",
    "                    to_delete.append(tok.i)\n",
    "\n",
    "        return to_delete\n",
    "\n",
    "    def get_DET(self, doc):\n",
    "        to_delete = []\n",
    "        for token in doc:\n",
    "            if token.pos_ == 'DET':\n",
    "                for tok in token.subtree:\n",
    "                    to_delete.append(tok.i)\n",
    "        return to_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "atg = model(df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "textd = '''A California man is facing murder charges after police say he intentionally rammed his vehicle into another, resulting in the death of three teenage boys.\n",
    "\n",
    "The incident took place Sunday around 10:30 p.m. (1:30 a.m. ET) about 60 miles southeast of Los Angeles near Corona, when the man, police said, rammed into a 2002 Prius, causing the driver of the vehicle to lose control and hit a tree. There were six teenagers in the car, including an 18-year-old driver, according to CNN affiliate KTLA.\n",
    "Three passengers were trapped in the car and had to be taken out using the Jaws of Life, according to CNN affiliate KCAL. One of the teens died at the scene, and the other five were taken to a hospital where two more died, a spokesperson with the California Highway Patrol told KCAL. Three of the boys had non-life threatening injuries, said California Highway Patrol Lt. David Yokley.\n",
    "Anurag Chandra, 42, was taken into custody without incident and was charged with three counts of murder and three counts of attempted murder, Yokley said. It is unclear if Chandra has an attorney.\n",
    "The initial investigation led authorities to believe it was a hit-and-run incident, however, witnesses came forward after following Chandra to his home and alerting police. Further investigation determined the crash was an intentional act. Authorities are now treating the incident as a homicide investigation, Yokley said.\n",
    "It is also unclear if Chandra or any of the boys knew each other, Yokley said.\n",
    "\"We really don't know, obviously there was some sort of contact. We're looking into those exact same questions of whether or not he was known to the victims,\" Yokley said. \"There was some sort of contact which led to this incident.\"\n",
    "Yokley said there's no indication that drugs or alcohol played a factor in this crash.\n",
    "CNN has reached out to the Riverside County District Attorney's Office and the Sheriff's Office.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Initial investigation led authorities to believe it was hit-and-run incident, however, witnesses came forward.',\n",
       " 'It is also unclear if Chandra or knew other, Yokley said. \\n',\n",
       " 'California man facing murder charges after police say he intentionally rammed vehicle, resulting in death of three teenage boys. \\n\\n']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atg.generate_titles(textd, 5, 5, 5, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model generates three titles for the above article text:\n",
    "'Initial investigation led authorities to believe it was hit-and-run incident, however, witnesses came forward.'\n",
    "'It is also unclear if Chandra or knew other, Yokley said.'\n",
    "'California man facing murder charges after police say he intentionally rammed vehicle, resulting in death of three teenage boys.'\n",
    "\n",
    "The last generated title is a perfect example to see the sentence compression in action. \n",
    "\n",
    "the original extracted sentence: 'A California man is facing murder charges after police say he intentionally rammed his vehicle into another, resulting in the death of three teenage boys.'\n",
    "\n",
    "the model prunes redundant words like 'a' and 'is' and the phrase 'rammed his vehicle into another' was compressed to 'rammed vehicle'.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
